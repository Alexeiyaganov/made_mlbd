{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "956f5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark as ps\n",
    "import warnings\n",
    "from pyspark.sql import SQLContext\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import trim\n",
    "from pyspark.sql.types import DoubleType,DateType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7f546568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5bf7f",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "247f83fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SKIENB~1\\AppData\\Local\\Temp/ipykernel_22924/1224509973.py:7: UserWarning: SparkContext already exists in this scope\n",
      "  warnings.warn(\"SparkContext already exists in this scope\")\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # create SparkContext on all CPUs available: in my case I have 4 CPUs on my laptop\n",
    "    sc = ps.SparkContext('local[4]')\n",
    "    sqlContext = SQLContext(sc)\n",
    "    print(\"Just created a SparkContext\")\n",
    "except ValueError:\n",
    "    warnings.warn(\"SparkContext already exists in this scope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a7e269d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('dataset/train.csv')\n",
    "df_test = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('dataset/test.csv')\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "53c985d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- comment_text: string (nullable = true)\n",
      " |-- toxic: string (nullable = true)\n",
      " |-- severe_toxic: string (nullable = true)\n",
      " |-- obscene: string (nullable = true)\n",
      " |-- threat: string (nullable = true)\n",
      " |-- insult: string (nullable = true)\n",
      " |-- identity_hate: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a98ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124633"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "# df = df.select(trim(\"id\"), 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate')\n",
    "df = df.withColumn(\"id\", trim(df. id))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3e2d8487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253637"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.dropna()\n",
    "df_test = df_test.withColumn(\"id\", trim(df_test. id))\n",
    "df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c5bd6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable(\"df\");\n",
    "df = sqlContext.sql(\"SELECT * FROM df WHERE LENGTH(toxic) == 1 AND LENGTH(id) == 16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "95850f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"toxic\",df.toxic.cast(DoubleType()))\n",
    "df = df.withColumn(\"severe_toxic\",df.severe_toxic.cast(DoubleType()))\n",
    "df = df.withColumn(\"obscene\",df.obscene.cast(DoubleType()))\n",
    "df = df.withColumn(\"threat\",df.threat.cast(DoubleType()))\n",
    "df = df.withColumn(\"insult\",df.insult.cast(DoubleType()))\n",
    "df = df.withColumn(\"identity_hate\",df.identity_hate.cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "84409dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- comment_text: string (nullable = true)\n",
      " |-- toxic: double (nullable = true)\n",
      " |-- severe_toxic: double (nullable = true)\n",
      " |-- obscene: double (nullable = true)\n",
      " |-- threat: double (nullable = true)\n",
      " |-- insult: double (nullable = true)\n",
      " |-- identity_hate: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "94529db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|000103f0d9cfb60f|D'aww! He matches...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|000113f07ec002fd|Hey man, I'm real...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|0001d958c54c6e35|You, sir, are my ...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|0002bcb3da6cb337|COCKSUCKER BEFORE...|  1.0|         1.0|    1.0|   0.0|   1.0|          0.0|\n",
      "|00031b1e95af7921|Your vandalism to...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|00037261f536c51d|Sorry if the word...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|00040093b2687caa|alignment on this...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|00070ef96486d6f9|Oh, and the girl ...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|000897889268bc93|REDIRECT Talk:Voy...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|0009801bd85e5806|The Mitsurugi poi...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|000f35deef84dc4a|There's no need t...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|000ffab30195c5e1|Yes, because the ...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|0011cc71398479c4|How could I post ...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|00128363e367d703|Not sure about a ...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|0015f4aa35ebe9b5|pretty much every...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|00169857adbc989b|Hi Explicit, can ...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|00190820581d90ce|FUCK YOUR FILTHY ...|  1.0|         0.0|    1.0|   0.0|   1.0|          0.0|\n",
      "|001c419c445b5a59|You had a point, ...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|001c557175094f10|In other words, y...|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|001dc38a83d420cf|GET FUCKED UP. GE...|  1.0|         0.0|    1.0|   0.0|   0.0|          0.0|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4dc5c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, val_set) = df.randomSplit([0.8, 0.2], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7b5e7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_set.drop('id').drop('comment_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7976554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-------+------+------+-------------+\n",
      "|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
      "+-----+------------+-------+------+------+-------------+\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  1.0|         1.0|    1.0|   0.0|   1.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  1.0|         0.0|    1.0|   0.0|   1.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  1.0|         0.0|    1.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  0.0|         0.0|    0.0|   0.0|   0.0|          0.0|\n",
      "|  1.0|         1.0|    1.0|   0.0|   1.0|          0.0|\n",
      "+-----+------------+-------+------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "79d19c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_set.select('id','comment_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "174342f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|              id|        comment_text|\n",
      "+----------------+--------------------+\n",
      "|000103f0d9cfb60f|D'aww! He matches...|\n",
      "|000113f07ec002fd|Hey man, I'm real...|\n",
      "|0001d958c54c6e35|You, sir, are my ...|\n",
      "|0002bcb3da6cb337|COCKSUCKER BEFORE...|\n",
      "|00031b1e95af7921|Your vandalism to...|\n",
      "|00037261f536c51d|Sorry if the word...|\n",
      "|00040093b2687caa|alignment on this...|\n",
      "|00070ef96486d6f9|Oh, and the girl ...|\n",
      "|000897889268bc93|REDIRECT Talk:Voy...|\n",
      "|0009801bd85e5806|The Mitsurugi poi...|\n",
      "|000f35deef84dc4a|There's no need t...|\n",
      "|000ffab30195c5e1|Yes, because the ...|\n",
      "|0015f4aa35ebe9b5|pretty much every...|\n",
      "|00190820581d90ce|FUCK YOUR FILTHY ...|\n",
      "|001c419c445b5a59|You had a point, ...|\n",
      "|001c557175094f10|In other words, y...|\n",
      "|001dc38a83d420cf|GET FUCKED UP. GE...|\n",
      "|001e89eb3f0b0915|Are you threateni...|\n",
      "|001ee16c46a99262|Thanks! Undeletio...|\n",
      "|0020e7119b96eeeb|Stupid peace of s...|\n",
      "+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c586e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.dropna()\n",
    "val_set = val_set.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98ec4c",
   "metadata": {},
   "source": [
    "HashingTF и IDF для логистической регрессии и SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b9e2402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average logreg auc for 2048 features: 0.5402676269243784\n",
      "average svm auc for 2048 features: 0.5081478320025472\n",
      "average logreg auc for 2304 features: 0.5920918408354721\n",
      "average svm auc for 2304 features: 0.5330903811308944\n",
      "average logreg auc for 2560 features: 0.6281785754869031\n",
      "average svm auc for 2560 features: 0.5811089030728485\n",
      "average logreg auc for 2816 features: 0.6662553673563634\n",
      "average svm auc for 2816 features: 0.6232626310513292\n",
      "average logreg auc for 3072 features: 0.6695717031519337\n",
      "average svm auc for 3072 features: 0.6753558618522904\n",
      "average logreg auc for 3328 features: 0.6652174503520631\n",
      "average svm auc for 3328 features: 0.6820810259036854\n",
      "average logreg auc for 3584 features: 0.6834253499518372\n",
      "average svm auc for 3584 features: 0.6874731060262619\n"
     ]
    }
   ],
   "source": [
    "for i in range(8,15):\n",
    "    tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\n",
    "    hashtf = HashingTF(numFeatures=2**i, inputCol=\"words\", outputCol='tf')\n",
    "    idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5)\n",
    "    auc_av_reg = 0\n",
    "    auc_av_svm = 0\n",
    "    for label in ['toxic', 'severe_toxic', 'obscene','threat','insult','identity_hate']:\n",
    "        log_reg=LogisticRegression(featuresCol='features', labelCol=label)\n",
    "        svm = LinearSVC(labelCol=label)\n",
    "        pipeline = Pipeline(stages=[tokenizer, hashtf, idf, log_reg])\n",
    "        pipeline2 = Pipeline(stages=[tokenizer, hashtf, idf, svm])\n",
    "    \n",
    "        pipelineFit_reg = pipeline.fit(train_set)\n",
    "        pipelineFit_svm = pipeline2.fit(train_set)\n",
    "        val_reg = pipelineFit_reg.transform(val_set)\n",
    "        val_svm = pipelineFit_svm.transform(val_set)\n",
    "        comment_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol=label)\n",
    "    \n",
    "        auc_av_reg += comment_eval.evaluate(val_reg) / 6\n",
    "        auc_av_svm += comment_eval.evaluate(val_svm) / 6\n",
    "    print('average logreg auc for', i*nFeatures, 'features:', auc_av_reg)\n",
    "    print('average svm auc for', i*nFeatures, 'features:', auc_av_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb048b",
   "metadata": {},
   "source": [
    "В данном случае можно сделать вывод, что с увеличением фичей классификаторы пропорционально увеличивают качество работы, логистическая регрессия в данном случае показывает лучший результат при маленьком количестве фичей в то время как SVM выходит вперед при большем количестве фичей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30485bd2",
   "metadata": {},
   "source": [
    "Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "448394b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql.functions import array, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2578d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=50, seed=42, inputCol=\"comment_text\", outputCol=\"features_w2vec\")\n",
    "word2Vec.setMinCount(10)\n",
    "word2Vec.setMaxIter(10)\n",
    "auc_av_reg = 0\n",
    "auc_av_svm = 0\n",
    "train_set = train_set.withColumn(\"comment_text\", split(\"comment_text\", \"\\s+\"))\n",
    "val_set = val_set.withColumn(\"comment_text\", split(\"comment_text\", \"\\s+\"))\n",
    "for label in ['toxic', 'severe_toxic', 'obscene','threat','insult','identity_hate']:\n",
    "    log_reg=LogisticRegression(featuresCol='features_w2ve', labelCol=label)\n",
    "    svm = LinearSVC(featuresCol='features_w2ve',labelCol=label)\n",
    "    pipeline = Pipeline(stages=[word2Vec, log_reg])\n",
    "    pipeline2 = Pipeline(stages=[word2Vec, svm])\n",
    "    \n",
    "    pipelineFit_reg = pipeline.fit(train_set)\n",
    "    pipelineFit_svm = pipeline2.fit(train_set)\n",
    "    val_reg = pipelineFit_reg.transform(val_set)\n",
    "    val_svm = pipelineFit_svm.transform(val_set)\n",
    "    comment_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol=label)\n",
    "    \n",
    "    auc_av_reg += comment_eval.evaluate(val_reg) / 6\n",
    "    auc_av_svm += comment_eval.evaluate(val_svm) / 6\n",
    "print('average logreg auc for', i*nFeatures, 'features:', auc_av_reg)\n",
    "print('average svm auc for', i*nFeatures, 'features:', auc_av_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eb694459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        comment_text|\n",
      "+--------------------+\n",
      "|[D'aww! He matche...|\n",
      "|[Hey man, I'm rea...|\n",
      "|[You, sir, are my...|\n",
      "|[COCKSUCKER BEFOR...|\n",
      "|[Your vandalism t...|\n",
      "|[Sorry if the wor...|\n",
      "|[alignment on thi...|\n",
      "|[Oh, and the girl...|\n",
      "|[REDIRECT Talk:Vo...|\n",
      "|[The Mitsurugi po...|\n",
      "|[There's no need ...|\n",
      "|[Yes, because the...|\n",
      "|[pretty much ever...|\n",
      "|[FUCK YOUR FILTHY...|\n",
      "|[You had a point,...|\n",
      "|[In other words, ...|\n",
      "|[GET FUCKED UP. G...|\n",
      "|[Are you threaten...|\n",
      "|[Thanks! Undeleti...|\n",
      "|[Stupid peace of ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set.select('comment_text').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc63b06e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
